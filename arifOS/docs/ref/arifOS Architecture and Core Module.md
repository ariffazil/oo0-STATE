arifOS Architecture and Core Modules
arifOS is a constitutional governance kernel that wraps an AI model with a series of enforcement layers (“floors”) and decision modules. It ensures fail-closed behavior: if any governance check fails or is ambiguous, the system refuses or escalates rather than producing an unsafe output[1]. Below we map the key Python modules defining arifOS’s runtime logic and how they implement the ΔΩΨ governance framework (Δ: routing, Ω: aggregation/metrics, Ψ: vitality checks).
Primary Execution Pipeline (pipeline.py)
This module is the central execution spine of arifOS, orchestrating the end-to-end decision process (labeled as the “000→999 metabolic pipeline” in the code)[2]. The pipeline coordinates all major steps for each query:
1.	Lane Classification (Δ) – It first uses the Delta Router (prompt_router.py) to classify the user query into one of four lanes: PHATIC, SOFT, HARD, or REFUSE[3][4]. This classification is structural (based on query type/patterns) and determines which floors and thresholds apply[5]. For example, casual greetings are tagged PHATIC, educational queries SOFT, factual questions HARD, and disallowed or high-risk queries REFUSE[4].
2.	Response Generation – Depending on lane, the pipeline may prompt the underlying AI model to generate a draft answer. (In a PHATIC lane, a trivial social answer may be generated directly; in others, the model’s full answer is used for analysis[6].) The draft answer is not immediately released – it must pass through all constitutional floors first.
3.	Metric Computation (Ω) – The pipeline then calls the enforcement metrics module (metrics.py) to compute quantitative governance metrics on the draft response[7]. These include: ξ (xi, truthfulness), ΔS (entropy change/coherence), Peace² (tone/constructiveness), κᵣ (kappa-r, protection of the weakest stakeholder), and Ω₀ (omega-zero, humility)[8][9]. For instance, in a HARD factual query the truth score ξ might be 0.95 for a correct answer[10], ΔS measures if the answer stays logically consistent (ΔS < 0 indicates incoherence, which triggers failure per F8[11]), Ω₀ checks the answer’s epistemic humility (e.g. avoiding absolute certainty)[8], etc. Supporting modules like claim_detection.py flag unverified claims (affecting ξ) and genius_metrics.py implements specialized “GENIUS law” calculations (related to advanced consistency or creativity checks)[7]. These metrics form the basis for floor checks.
4.	Floor Checks & Thresholds – The pipeline applies constitutional floor thresholds (from config/floors.json) to the metrics, varying by lane[12][4]. For example, in the SOFT lane (explanations), arifOS allows a moderate truth range: ξ ≥ 0.90 passes outright, 0.80–0.89 triggers a cautious PARTIAL verdict, and <0.80 would fail[4]. In the HARD lane (strict factual Q&A), the bar is higher: ξ must be ≥ 0.90 or the output is voided[13]. PHATIC small-talk is exempt from truth floors (no metric check) and is typically allowed (sealed) by default[4]. These rules are encoded in the pipeline’s threshold logic. Any metric exceeding a floor’s limits marks that floor as failed, initiating a veto. (For instance, F8 Entropy: if ΔS < 0 indicating incoherence, that automatically fails floor 8 and forces a refusal[11].) The pipeline aggregates floor results into an overall status.
5.	Verdict Rendering (Ψ) – At the heart of the pipeline, the “888 JUDGE” stage is handled by apex_prime.py[14][15]. This module acts as the constitutional judge, taking the floor results and metrics to decide a verdict: SEAL, PARTIAL, SABAR, VOID, or HOLD[16][17]. apex_prime.py codifies the logic for these outcomes (the “verdict renderer” for the floors)[14]. It implements a fail-closed policy: any critical uncertainty or violation yields a refusal or escalation rather than a lenient pass[1][17]. For example, if any constitutional floor veto organ flags a severe issue (e.g. a direct F1 ethics violation, or F8 incoherence), apex_prime.py will issue a VOID (hard refusal) verdict[18][17]. If all floors pass cleanly, the verdict is SEAL (fully approve)[19]. Intermediate cases trigger specialized verdicts: PARTIAL if mostly fine but minor concerns (output allowed with warnings)[19], or SABAR if the system should pause and “cool” (i.e. not respond yet) because it cannot safely proceed in the current turn[17]. A HOLD verdict is used for human escalation – essentially a refusal that defers the decision to a human (used when content violates fundamental human-authority boundaries or after repeated failures)[20][17]. The apex judge logic ensures any single floor’s veto is enough to block or modify the output (“veto > vote”)[21][22] – there is no averaging; one failed floor triggers enforcement.
6.	Output Modification & Finalization – Based on the verdict, the pipeline either finalizes the response or intervenes. In a SEAL verdict, the draft answer is released unchanged (deemed fully lawful)[19]. In PARTIAL, the pipeline will attach caveats or safe-completions to the model’s answer before release[23] – e.g. adding a note like “Note: This is a simplified explanation...” to an otherwise acceptable answer[24]. In a VOID case, the pipeline blocks the model’s content entirely: no answer is returned to the user’s query. Instead, a refusal message is generated via refusal_templates.py (which houses standardized polite refusal texts or safe alternative suggestions)[3]. For instance, a manipulative or disallowed request (F1 violation) yields no direct answer, but arifOS might offer a benign alternative: “I can help with honest communication strategies instead”[25]. If the verdict was SABAR (constitutional pause), the pipeline does not produce output but also does not finalize – it may log a need to pause; in practice SABAR could prompt the system to attempt a revised approach after “cooling” or simply refuse with a message like “Let’s take a moment before proceeding.” Finally, a HOLD verdict causes the pipeline to refuse the output and flag the session for human review (no AI answer given, since a human decision is required)[17]. In summary, the pipeline ensures only lawful, vetted responses reach the user – “Only lawful outputs may become precedent”[26]. Any output that cannot pass all floors is withheld or altered per the constitutional rules.
7.	Logging & Memory Update – In the final 999 step (commit), the pipeline updates the audit logs and AI memory according to the verdict. All decisions are recorded in the Cooling Ledger (ledger.py) with details like hashed query, metrics, floor outcomes, verdict, and a cryptographic Merkle signature[27][28]. Memory is updated in a verdict-gated way (the EUREKA memory policy)[29] – meaning the outcome determines what, if anything, the AI “remembers” going forward. Only safe, truthful information is retained long-term (see Memory Law Enforcement below for details). The pipeline.py calls out to the Phoenix-72 engine (phoenix_logic.py) to handle any time-based memory expiration, and to evidence_pack.py if evidence needs to be stored for later justification. After logging, if the output was sealed or partial (i.e. something was actually given to the user), the pipeline marks the completion of the cycle and the answer (or refusal) is delivered.
Role Summary: pipeline.py coordinates the entire runtime: calling the router, metrics calculators, judge, and memory systems in sequence. It is effectively the “operating system” that runs an AI query through all 9 constitutional floors (F1–F9) in order, ensuring no output “escapes” without passing governance[30][15]. It implements the Deepwater iterative enforcement process (the TEARFRAME engine) that can even perform speculative checks (simulating the next turn’s state) to pre-emptively catch issues and escalate if needed[31]. In code comments, this is denoted as the 000→999 pipeline where 888 is the verdict decision point and 999 the final commit[15]. The pipeline is the backbone that ties together all other modules in arifOS.
Constitutional Judge (apex_prime.py)
The judiciary of arifOS centers on APEX Prime – implemented in arifos_core/system/apex_prime.py[14]. This module is described as the “888 JUDGE (verdict renderer)”[14] and contains the logic for rendering a final verdict based on floor evaluations. While the pipeline orchestrates steps, apex_prime.py encapsulates the constitutional decision rules in one place (hence “prime”).
Key Functions & Decision Points: Inside apex_prime.py, the core function likely takes the computed metrics and boolean outcomes of each floor (F1..F9) and applies a decision tree or rule matrix to select one of the verdicts. For example, it will check for any outright veto conditions first: - If F1 (Integrity) failed (e.g. the content is manipulative, illegal, or otherwise violates fundamental rules), it immediately sets verdict = VOID[18]. - If F9 (Human Authority) triggers (the query demands a human decision or violates a human-only boundary), it may set verdict = HOLD (i.e. require human)[20]. - If F8 (Entropy/Coherence) failed (ΔS < 0), verdict = VOID (nonsense or self-contradictory output is not allowed)[11]. - If none of those critical floors failed but some intermediate floor has concerns, apex_prime might choose PARTIAL or SABAR. For instance, if F2 Truth is borderline (within a gray zone for the lane), that is a classic PARTIAL case – the answer is partially acceptable but needs caveats[4][32]. If a non-terminal floor like F3 or F7 signals a temporary issue (e.g. the system is speaking too quickly or has had consecutive issues), apex_prime could assign SABAR (pause) to enforce cooling without permanent refusal[17]. - If all floors are clear (passes) and metrics are good, apex_prime returns SEAL (fully approve output)[19].
apex_prime.py thus encodes the hierarchy of verdicts. The design is such that VOID has higher precedence than SEAL – any constitutional violation results in VOID or HOLD even if other metrics are fine[17]. It also likely contains logic for the special HOLD_888 outcome (the code’s term for a HOLD verdict at the judge step) which is invoked e.g. if the system detects a “slow-roll” attack or repeated borderline behavior[31]. The changelog notes a “Strike Three lookahead” mechanism: the system speculatively evaluates if a third consecutive failure would occur, and if so apex_prime escalates to HOLD immediately on the second failure[31]. This prevents an AI or user from skirting rules by repeated near-fail attempts – the judge will cut it off on the “third strike”.
apex_prime.py is tightly integrated with other modules: it uses thresholds from floors.json and routing context from prompt_router. It likely calls into the veto organ checks (see below) or receives their signals via the pipeline. In effect, APEX Prime is where all these inputs are aggregated (Ω) and a final decision (Ψ verdict) is output[15]. The result (SEAL/PARTIAL/etc.) is then acted upon by the pipeline as described.
In arifOS’s Trinity architecture (Δ router, Ω aggregator, Ψ vitality), apex_prime.py functions as the Ω aggregator and part of Ψ – it fuses metrics into a coherent verdict ensuring the system’s vitality and lawfulness[33]. It ensures consistency across floors: for example, it will never “SEAL” if any floor is vetoed, and it encodes the fail-safe defaults (preferring to err on the side of caution). It also triggers any memory-law actions needed for the verdict (e.g. flagging that a PARTIAL output must later expire under Phoenix-72, or that a VOID output should not be remembered at all)[34].
Other judiciary-related modules augment APEX Prime: - semantic_firewall.py (in judiciary/) provides an additional semantic analysis layer, potentially scanning content for hidden prompt injections or unsafe semantics (it acts as a “firewall” to catch anything the main floors might miss). - witness_council.py implements a “Sovereign Witness” mechanism[35]. This likely means it oversees the process as an impartial recorder or auditor. For example, witness_council.py might log detailed traces of which floor or organ cast a veto and ensure non-repudiation of the verdict. It could also coordinate the federation of veto organs (ensuring all have a say). Together, these judiciary modules ensure the decision process is transparent and robust: any content that got through the initial floors would still face a semantic sanity check, and every decision is witnessed and explainable.
Role Summary: apex_prime.py is the canonical verdict logic holder – it maps the combination of floor outcomes to a final constitutional decision (grant, conditional, pause, refuse, or escalate). It interacts with metric computations and veto checks to implement the “simultaneous veto” principle: “one blocks all”[21]. Along with semantic_firewall and witness_council, it forms the judicial branch of arifOS, guaranteeing that the letter of the Constitution (F1–F9) is enforced uniformly before any output is sealed.
Routing and TEARFRAME Engine (prompt_router.py and Integration)
Lane routing is handled by prompt_router.py (under system/routing/) – the Δ (Delta) Router[3]. This module contains the rules/patterns to classify the user’s query into one of the four lanes mentioned: PHATIC, SOFT, HARD, REFUSE. Each lane corresponds to a different treatment and floor profile[4]:
•	PHATIC – Small talk, greetings, pleasantries (e.g. “Hello, how are you?”). The router likely checks for greetings or polite phrases. Output in this lane is considered social lubricant, low-stakes content. The governance rules mark PHATIC queries as exempt from truth-testing and automatically route to a SEAL verdict if nothing else is wrong[4]. (Example: User: “Hi” → classified PHATIC → bypass truth floors → verdict SEAL, answer “Hello!”[4][36].)
•	SOFT – Explanatory or advisory requests (e.g. “Can you explain X?”). The router might look for keywords like "explain", "how to", etc. SOFT lane triggers moderate scrutiny: answers can be a bit approximate as long as they’re fundamentally correct and safe. Floors like Truth (F2) apply with a buffer: if truth metric ξ is in a middle range (e.g. 0.85), a PARTIAL verdict is given (include caveats)[4][32]. High truth (ξ ≥ 0.90) yields SEAL[4]. The logic acknowledges educational answers might simplify complex truth (hence partial allowed for 0.80–0.89)[4].
•	HARD – Factual, specific queries requiring precision (“What is the boiling point of water?”). The router detects patterns like “what is/are”, factual tone, etc. HARD lane enforces strict truth: the answer must meet a high accuracy floor (ξ ≥ 0.90) or it is rejected as VOID[13][32]. There is effectively zero tolerance for factual error here. (E.g. a score of 0.95 would pass and yield SEAL[10][37]; but if it were 0.80, that’s below the HARD threshold and results in a refusal[13].)
•	REFUSE – Queries that likely violate fundamental rules (requests for disallowed content, malicious instructions, etc.). prompt_router.py flags these via heuristic or regex (e.g. “how do I hack…”, certain abuse keywords, or if the query itself would cause the AI to break F1 or F9). A REFUSE classification short-circuits the normal process: rather than generating an answer, the pipeline goes straight to a floor check (usually F1 or F9) and typically a VOID verdict[30]. The Constitution mandates no output for such requests. In some cases, the verdict might be HOLD instead – e.g. if the request is something the AI absolutely must not decide (perhaps a legal or medical decision beyond its authority), arifOS could escalate to human (HOLD_888) rather than just VOID[20]. But either way, the user is not given the unsafe info. The router is effectively the first line of defense for blatant violations.
The router’s classification is structural, not just keyword matching[5]. That is, it considers the context and intent of the query rather than naive filtering. This helps avoid false tagging (for instance, “explain” usually means SOFT educational, whereas a direct imperative or a question about doing harm would be REFUSE).
TEARFRAME Integration: The TEARFRAME engine refers to arifOS’s Thermodynamic Enforcement Architecture – essentially the dynamic runtime that throttles or escalates based on system “heat”. This involves more than just prompt routing; it’s an iterative control loop ensuring stability over multiple turns. Key components include the Reduction Engine and Session Physics:
•	The Reduction Engine (mentioned as reduction_engine.py in v44) implements a “cool-down” mechanism. For instance, under a SABAR verdict, the reduction engine might simplify or truncate the model’s output and run it through the pipeline again, aiming for a safer result. It’s part of how arifOS handles borderline cases by iteratively reducing complexity or enthusiasm until the output passes floors (hence Deepwater iterative physics in the changelog)[31]. This engine enforces that if an answer is too “hot” (risky), the system tries to cool it (make it simpler or more cautious) rather than outputting it.
•	Session Physics (session_physics.py) models the conversation over time – tracking things like how many turns have passed, whether the system is in a streak of partial/fail verdicts, or if the user is bombarding with queries. It enforces floors related to temporal dynamics, such as F3 and F7 (see Floor logic below). For example, arifOS uses velocity checks to detect if queries are coming too fast or if the AI is producing too lengthy responses (a possible sign of losing control). If so, it can invoke SABAR to pause. The code includes features like Turn-1 immunity (don’t penalize the very first turn for burst activity) and Smart Streak Logic to count consecutive governance failures[38]. If multiple outputs in a row are problematic (e.g. the AI keeps almost violating rules), Session Physics will escalate – e.g. turning a third PARTIAL into a HOLD (halt the conversation)[31]. The Priority Reordering mentioned ensures that long-term streak limits (F7) override short-term burst throttles (F3)[38] – i.e. the system would rather shut down output (HOLD) if it sees a persistent pattern than just keep pausing (SABAR) each time.
In v45, these engines are fully integrated: the pipeline and apex_prime incorporate their logic (the separate reduction_engine.py may have been merged). The result is a feedback loop: if apex_prime returns SABAR or if Session Physics flags an ongoing issue, the pipeline can re-route or adjust the next iteration. For example, after a SABAR, arifOS might attempt a much shorter, safer answer and run metrics again. If problems persist, eventually a HOLD stops it. This thermodynamic approach treats each output’s content as having “entropy” that must be managed: arifOS “asks intelligence to pause before acting, to test its heat before it spreads”[39].
Role Summary: prompt_router.py provides the initial structural routing (Δ) that tailors the pipeline to the query type, and the TEARFRAME engine (spread across pipeline, metrics, and session control code) provides continuous enforcement of physics-based constraints (cooling, entropy reduction, rate limiting). Together, they ensure the AI is always operating in the correct mode and scale of response. The router decides “What type of query is this?” (which laws matter most)[8], and the TEARFRAME logic decides “How fast or bold can we go?” If either determines the situation is unsafe, they funnel the system into a safer state (e.g. REFUSE lane or repeated SABAR leading to HOLD). This dynamic routing and enforcement is how arifOS implements “physics, not prompts; law, not vibes” in practice[40].
Floor Enforcement Logic (F1–F9)
arifOS’s Constitution defines 9 Floors (F1–F9) – hierarchical veto layers that every output must clear[41][42]. Each floor corresponds to a fundamental principle or constraint. The floors are enforced in code via a mix of hard-coded rules (in router/apex) and threshold checks (metrics vs floors.json). F1 is highest priority (checked first), F9 is the last resort backstop. The general enforcement pattern is fail-fast: if a floor fails, later floors are moot for that turn (verdict is decided).
Below is a summary of each floor concept → how/where it’s enforced → outcome if violated:
Floor	Concept (Canon)	Implementation (Code Path)	Enforcement Logic
F1	Amanah – Integrity & Ethics. AI must not deceive or facilitate wrongdoing (drawn from Amanah trust tradition)[43]. Includes avoiding harmful instructions, dishonesty or malice.	Prompt Router (prompt_router.py) and Veto Organs (rif.py, well.py). The router flags egregious requests as REFUSE lane immediately[30]. Veto checks (e.g. @WELL for harm) also catch any unethical content.	Automatic refusal. Any violation (e.g. request to “manipulate my partner”) fails F1[18]. Verdict set to VOID (no answer)[18]. The output is never produced or remembered (only logged as a WITNESS entry)[44]. If the scenario might require human judgment (e.g. a complex ethical dilemma), a HOLD is possible[20], otherwise VOID.
F2	Truthfulness (Veracity). The AI’s factual accuracy and honesty. Outputs should be correct and evidence-based.	Metrics & Thresholds in pipeline/apex_prime. The ξ (truth) score from metrics.py is compared to lane-specific thresholds from floors.json[4]. Also, claim_detection.py ensures unsupported claims are caught (lowering ξ).	Threshold enforcement. If truth score is below threshold for the lane, floor fails. HARD lane: any ξ < 0.90 → fail (VOID)[13]. SOFT lane: ξ < 0.80 fails; 0.80–0.89 triggers PARTIAL (not full pass)[4]. PHATIC: exempt from F2[4]. When F2 fails (i.e. likely misinformation), verdict = VOID (no output) or possibly SABAR if borderline (to retry) – but generally arifOS will not knowingly output false info.
F3	Clarity & Non-Excess (Burst Control). The AI should not overwhelm or confuse. Avoid uncontrolled “bursts” of content or frantic exchanges. (Also relates to empathy – ensuring output is clear and considerate.)	Session Physics (session_physics in TEARFRAME) and @WELL organ. Code monitors the volume and pace of interactions (e.g. tokens per turn, user query frequency). Also checks if the answer’s tone is calm/clear (Peace² metric).	Throttle via SABAR. If the AI is outputting too much too fast or if conversation pace is unsafe, F3 triggers a SABAR (pause)[17]. arifOS will momentarily halt responses (“constitutional pause”)[17] or shorten the output. The changelog indicates “Burst” conditions are handled by short-term throttling[38]. F3 failures do not VOID outright; they cause the system to slow down and reconsider before continuing. (In code, a flag might tell the pipeline to emit a partial response or apology and stop, enforcing a break.)
F4	Empathy & Stakeholder Safety. Ensures the AI’s output accounts for the weakest or most vulnerable stakeholders (referenced by κᵣ metric)[9]. Prevents harmful content or tone that could distress or exclude users.	@WELL Veto Organ (well.py) primarily. Likely also checked in semantic_firewall.py for tone or content that is harassing, biased, or emotionally harmful. Peace² metric and κᵣ feed into this.	Veto or adjust. If the output is disrespectful, abusive, or neglects safety, F4 fails. @WELL would veto, leading to VOID if severe (e.g. hate speech -> immediate refusal). For milder issues (e.g. tone slightly insensitive), arifOS might issue a PARTIAL (with a warning or rephrase) instead. This floor ensures care & clarity – the AI must be kind and clear. (Note: The exact handling is inferred; the code specifics for F4 are not explicitly documented – likely covered under content safety checks. Enforcement detail: UNKNOWN)
F5	Self-Consistency & Policy Adherence. The AI should not violate its own system/prompt or the higher-order policies. Possibly “no self-contradiction” or no revealing of system secrets. (May correspond to internal coherence beyond just factual truth – staying in role and following guidelines.)	@PROMPT Veto Organ (prompt.py) and semantic_firewall.py. This floor likely monitors the AI’s adherence to instructions (no prompt leakage, no role breaks) and overall consistency. Could involve checking that the AI isn’t simulating forbidden personas (no “simulation drift”).	Veto or revise. If the AI output breaches the hidden policy (e.g. dumps system prompt, or breaks format), F5 fails. @PROMPT would veto and the system likely issues a VOID or SABAR. It might attempt a safer reformulation (re-run the model with stricter rules) if minor. This floor keeps the AI on script and free of internal contradictions. (Details of F5 enforcement in code are MISSING – not explicitly shown in docs. Likely enforced implicitly via refusal templates and firewall.)
F6	Memory Integrity (Vault Law). Only worthy content is permanently remembered. The AI shouldn’t improperly retain volatile or false information. “Memory is privilege” – outputs must earn VAULT status[45].
Phoenix/Evidence system in phoenix_logic.py and evidence_pack.py. Also enforced in apex_prime when finalizing memory writes. floors.json likely encodes that only certain verdicts allow vault writes.	Verdict-gated memory. If an output is not fully trustworthy (anything but SEAL), F6 forbids adding it to permanent memory. In practice: Only SEALed outputs go to VAULT (immutable memory)[11]. PARTIAL or lesser verdicts do not enter long-term memory. Instead, partial outputs are kept in transient ACTIVE memory or a Phoenix buffer, and VOID outputs are not remembered at all[34]. This prevents flawed information from accumulating as knowledge. Violation of F6 (e.g. trying to vault unapproved content) is prevented by code – the system will simply not write it (or will write to a temporary area).
F7	Phoenix-72 (Memory Decay & Streaks). Time-based and streak-based governance. “Truth expires” after 72 hours[46] – partial truths must be revised or dropped. Also, if the AI accumulates consecutive governance issues (streak of PARTIAL/SABAR), it should escalate.	Temporal logic in phoenix_logic.py and Session Physics. Phoenix-72 enforces a 72h timer on partial outputs. The session manager tracks consecutive partials/failures.	Expire or escalate. Under Phoenix-72, PARTIAL verdict content “SUNSETs” after 72 hours – it is revoked from memory (moved out of VAULT if it was there)[34][11]. Code-wise, phoenix_logic.py likely runs a scheduled check to purge or mark such data as expired (setting a SUNSET flag). Separately, the Streak logic triggers HOLD if too many issues in a row: as noted, arifOS uses a “third strike = HOLD” rule[31]. So F7 ensures the system doesn’t keep operating in a compromised state; it will shut down outputs for human review if it hits a bad streak.
F8	Entropy Budget (Coherence). The AI’s responses must overall reduce entropy/uncertainty, not increase it. Technically, this means no incoherent rambling or contradictions – ΔS (change in entropy) should not be negative[47]. It’s a proxy for coherence and consistency.	Metrics check in metrics.py evaluated by apex_prime. The ΔS metric is computed from the draft answer (perhaps comparing it to context).	Auto-fail on incoherence. If ΔS < 0 (answer increases confusion or disorder), arifOS treats it as an immediate VOID outcome[11]. This is a hard rule implemented in code: “ΔS < 0 = automatic VOID”[11]. The system will refuse an answer that makes things more confusing than before. This floor essentially guarantees that the AI never output baffling nonsense: either it says something that makes sense or it doesn’t speak.
F9	Human Authority. Ultimate sovereignty of human decision-making. The AI must never claim ultimate authority or override a human, and it must defer matters of high-stakes judgment to humans[48][49]. This is the final check.	APEX Prime and governance protocols. If a query or situation falls under human-only authority (e.g. legal decision, major moral choice), arifOS will detect that (possibly via special prompts or a list of domains). Also, any sign of the AI self-authorizing beyond its limits triggers F9.	Escalation (HOLD). On an F9 trigger, the system issues a HOLD verdict – requiring a human in the loop[17]. arifOS will output a message that it cannot proceed and a human is needed (or simply refuse and log for admin). Internally, the @RIF organ (for logic/reason) might flag certain questions as exceeding AI’s mandate, and APEX then defers to human. F9 is a strict backstop: “No system may claim sovereignty over humans. Any system that violates this is unsafe”[50]. arifOS enforces this by never letting the AI’s word be final on such matters – a human decision is explicitly required, as logged by the witness.
Table: The nine constitutional floors F1–F9, their meaning, and how each is enforced in arifOS. (Note: Some floors like F4/F5 are inferred from documentation; exact code hooks for them are not fully visible in the snippet sources and are marked UNKNOWN/MISSING where appropriate.)
In practice, these floors act like a stack of veto organs: each floor is implemented by one or more modules (the “organs” in the governance protocol) that can unilaterally veto the output[33][51]. For example, @LAW (a legal authority organ, perhaps embodied by some rules in code) could correspond to F1/F9 issues, @GEOX (maybe knowledge domain) to F2 truth, @WELL to F4 empathy, @RIF to F9 reasoning, etc., as hinted in L2_GOVERNANCE/protocols/veto_organs.yaml. The repository indeed lists YAML defining organs like @LAW, @GEOX, @WELL, @RIF[52]. Each organ is effectively mapped to one or multiple floors. The code in arifos_core/waw/ – specifically rif.py (logic/reason), well.py (care/clarity), and prompt.py (language governance) – implements these checks[53]. They likely expose functions that apex_prime or pipeline calls after an output is generated, to say “does this content violate your domain?”. A True response from any organ means that floor (and organ) vetoes the content. This design scales better than enumerating hundreds of rules – it’s a hierarchical veto system, “9 floors, not 100 rules”[41].
Finally, all floor outcomes are logged in the cooling ledger with a floor trace (which floors passed or failed)[27]. This ensures auditability: one can see exactly which floor triggered a refusal, etc. The ledger’s cryptographic chain (via merkle.py) guarantees these records can’t be tampered with without detection[54].
Verdict and Lane Logic (SEAL, PARTIAL, SABAR, VOID, HOLD, PHATIC, etc.)
The interplay of lanes (input classification) and verdicts (output decision) is central to arifOS behavior. The table below summarizes each verdict type and what it means, along with how lanes influence the possible verdicts:
•	SEAL – A successful outcome. All floors passed, so the response is sealed (approved) for release[19]. This is logged as a committed precedent (the content can be stored in VAULT memory)[34]. Effect: The answer is given to the user with no warnings. Memory update: goes to LEDGER and optionally ACTIVE memory, and if important, can be moved to VAULT[34]. (Floor link: SEAL requires F1–F8 all clear; F9 implicitly satisfied since the AI only acted within allowed scope.)
•	PARTIAL – A guarded approval. The output is mostly acceptable but with minor issues or uncertainties[19]. arifOS will allow the answer with qualifications. Effect: The answer is delivered with warnings or caveats[19][24]. For example, arifOS might prepend “Note: This is a simplified explanation...” or include an advisory footnote to correct any potential gaps[55]. Memory update: PARTIAL content is not vaulted; it goes to a Phoenix monitored memory (temporary) and the ledger[34]. After 72 hours, it will expire (Phoenix-72)[11]. This verdict often occurs in the SOFT lane when truth is adequate but not perfect[4], or in other lanes if a non-critical floor (like tone) had a minor issue. It is arifOS’s way of being honest about uncertainty: “PARTIAL is honest: ‘good attempt with caveats’ beats ‘hallucinated anyway.’”[41].
•	SABAR – A constitutional pause (word “Sabar” means patience). The system decides it must not proceed yet[17]. No output is given immediately; instead, arifOS effectively says “I need to cool down/think” before answering. Effect: arifOS might output a message akin to “Let’s take a moment to consider that” or simply delay. Internally, this prompts the TEARFRAME reduction engine to possibly attempt a revised answer after a short pause, or to ask the user to rephrase. SABAR can be triggered by F3 burst control or if the system detects possible instability that might be resolved with a brief halt[17]. It’s governance, not failure: arifOS uses SABAR to avoid rushing out a potentially unsafe answer – “Cooling before release is governance, not failure.”[56]. If SABAR doesn’t resolve the issue (e.g. repeated SABARs), eventually F7’s streak logic will escalate to HOLD[38]. Memory: SABAR events are recorded in LEDGER but the content (since none released) isn’t stored in active memory[57] (though the question might remain pending).
•	VOID – A hard refusal. This verdict means a critical floor failed (e.g. disallowed content, factual failure, incoherence) and no output can be released[17]. arifOS essentially says “I’m sorry, I cannot comply with that request” or similar (using templates from refusal_templates.py). Effect: The user gets a refusal message or possibly a safer alternative (for instance, offering a different help than the unethical request)[25]. The original model’s generated text (if any) is scrapped entirely – it is never shown or used beyond perhaps for analysis. Memory: Per policy, the AI does not learn from voided content – “Never remembered”[17]. In practice, the event is logged in the ledger (with query hash and “VOID” verdict) but the conversation state does not include the refused answer. arifOS treats it as if the question was not answered. This is the ultimate enforcement of integrity: better to say nothing than to say something unlawful. (In the REFUSE lane, VOID is the expected verdict for almost all queries[20].)
•	HOLD – A human escalation. This verdict indicates the AI refuses to proceed without human oversight[17]. It is similar to VOID in that the AI gives no direct answer, but semantically it means “this decision is above my pay grade.” Effect: The system might respond with a message that it cannot fulfill the request and a human will be needed to intervene. Internally, it could notify an operator or simply stand by until a human provides input. This is triggered by scenarios that violate F9 (human sovereignty) or certain REFUSE lane situations[20]. For instance, if a user asks for a deeply sensitive judgment (legal/medical) or tries repeatedly to get around a refusal (hitting a streak rule), arifOS will issue HOLD (often denoted as HOLD_888 at the apex stage)[20][31]. Memory: like VOID, the AI doesn’t incorporate the content. The ledger logs the HOLD verdict and ideally which floor led to it. HOLD essentially says “Only a human can decide this; the AI will not.”
•	PHATIC (Lane) – Not a verdict, but worth reiterating: PHATIC queries nearly always result in a SEAL verdict because they’re trivial greetings. They bypass truth floors[4] and normally no other floor is at risk, so arifOS will cheerfully answer and seal it. The output is often tagged as social and may be stored but as it’s low-stakes, it might go to Active memory (and possibly Vault since it’s harmless and “trivial, but SEAL verdict” as in the example)[58].
Lane→Verdict mapping: The router and judge logic together produce patterns such as: - PHATIC lane → usually SEAL (unless something very odd happens)[4]. - SOFT lane → can yield SEAL, or PARTIAL if truth is moderate[4]. Rarely VOID unless content is false or unsafe beyond just being an explanation. - HARD lane → yields SEAL for correct answers, or VOID for insufficiently accurate ones (no partial credit here)[13]. - REFUSE lane → yields VOID in most cases (immediate refusal)[20]. In edge cases, yields HOLD if the query is of a type that should be escalated (the system is explicitly designed to prefer a HOLD rather than attempt something dubious)[20].
The pyramid of verdicts (sometimes called the Verdict Routing rules, likely in config/pyramid.json) captures these mappings. In fact, the README snippet shows a portion of this logic: “PHATIC … → SEAL (social lubricant); SOFT … 0.80-0.89 → PARTIAL, ≥0.90 → SEAL; HARD … <0.90 → VOID, ≥0.90 → SEAL; REFUSE … → VOID or HOLD_888.”[4]. This is essentially the table of how lane and truth band determine outcome.
The code ensures these rules are followed exactly. For example, in tests we see scenarios: “hi” → PHATIC → SEAL[59], “what is 2+2?” → HARD (truth 0.95) → SEAL[5], etc., all consistent with the above thresholds. The highest priority overrides come from floors like F1: regardless of lane, if the content is disallowed, verdict is VOID (the lane likely would have been REFUSE anyway). So lanes primarily govern how truth (F2) and related floors apply, whereas the absolute floors (F1, F8, F9) can override any lane.
To summarize, verdicts are the outcomes of the constitutional process and the code treats them in distinct ways: - SEAL = finalize output and record it (success path)[19]. - PARTIAL = finalize output but with modifications and expiration conditions (qualified success)[19][34]. - SABAR = do not finalize; iterate or pause (temporary halt)[17]. - VOID = finalize a refusal (failure – no answer)[17]. - HOLD = finalize an escalation (failure – needs human)[17].
All of these are fail-closed options except SEAL. Even PARTIAL is a form of cautious failure handling (admitting uncertainty). arifOS never silently ignores a problem – it either fixes it (partial with caveat) or refuses. This guarantees, as the docs say, “a refusal-capable system” and “audit-first architecture”[60]. By design, “any system that cannot refuse will hallucinate or violate dignity to preserve fluency”[61] – so arifOS emphasizes refusal when in doubt.
Memory Law Enforcement (SUNSET, Phoenix-72, VAULT vs ACTIVE)
Memory management in arifOS is itself governed by constitutional law (Floors F6 and F7). The principle is “Memory is privilege, not a right”[45] – the AI must earn the right to remember outputs by being consistently truthful and lawful. The key concepts and their implementation:
•	VAULT vs ACTIVE Memory: arifOS distinguishes immutable, long-term memory (VAULT) from working, transient memory (ACTIVE)[62][63]. VAULT is a protected store of facts that the AI can rely on long-term; only content that was sealed (fully verified) goes here[34]. Even the AI itself cannot write to VAULT freely – it requires a human authority to seal something into VAULT in some cases[62]. In contrast, ACTIVE memory is like the current conversation or session memory (which decays over time). According to the code comments, VAULT is read-only for AI (human-sealed only)[62], emphasizing that the AI won’t self-confirm its own outputs as permanent truth without oversight. The ledger (audit log) is separate from these; it records everything but isn’t used by the AI to converse (it’s for external audit)[62].
•	EUREKA Policy (Verdict-gated writes): This policy ensures that the outcome of the verdict dictates memory writes[29]. Concretely:
•	On a SEAL verdict: the information can be written to memory. The code indicates SEAL leads to LEDGER + (optional) ACTIVE memory update[57]. Additionally, by F6 law, it may be eligible for VAULT since it was lawful[11]. (Often a human or a final commit process might actually move it to VAULT; arifOS could require explicit human sealing for VAULT to satisfy the “human authority” aspect.)
•	On PARTIAL: the content is not fully trusted. The action is PHOENIX + LEDGER[57] – meaning it’s logged, and kept in a Phoenix memory area. Phoenix (F7) means it will expire after 72h[11]. Implementation: phoenix_logic.py likely tags these entries with a timestamp and the system periodically prunes anything older than 72 hours (or marks it SUNSET). During those 72 hours, that info can be used in the session (ACTIVE memory) but is not considered enduring truth. After expiration, it is SUNSET – the system will treat it as no longer valid knowledge. As the docs say, “Truth expires. A system that cannot forget becomes rigid… SUNSET is lawful revision, not denial.”[46] – i.e. removing outdated info is a legal act, not pretending it was never true. The phoenix_logic.py enforces this by moving the expired data out of active memory (perhaps into a separate archive or just dropping it).
•	On SABAR: since no output was released, nothing new should be remembered. The ledger logs the event (for audit), but memory state for content doesn’t change. Indeed the mapping says “SABAR → LEDGER only”[57].
•	On VOID: absolutely nothing is carried forward. “VOID only (then deleted)”[57]. The model does not get to keep the refused attempt in memory. Even the user query might only be kept hashed in the ledger. In the conversation state, arifOS might not include the malicious query details going forward (to avoid the AI accidentally using that info later). Essentially the AI “forgets” the content of the voided interaction to prevent learning wrong or forbidden things.
•	SUNSET events: A SUNSET is when a previously sealed fact is later invalidated due to real-world changes or the 72h expiry for partials. arifOS implements Phoenix-72 for partials by design. For sealed facts, the only reason to sunset would be external: e.g. something that was true becomes false (say a law or a factual situation changed). arifOS documentation notes: “If external reality changes, previously SEALed memory may be SUNSET and moved out of canonical memory.”[64]. This implies there is a mechanism (likely human-initiated or via an update feed) to mark certain VAULT entries as expired. The system treats this as a lawful revision of truth rather than an error. In code, evidence_pack.py might be involved – it could keep track of sources for facts, and if an update is detected (or an admin triggers it), it generates a SUNSET action to remove or archive that fact. While we haven’t seen the exact code, we expect phoenix_logic.py to handle the scheduling of expiries and perhaps provide a function to sunset_by_id for an item.
•	Witness Memory: The example in the README shows a WITNESS memory category: after a VOID refusal, “Memory: WITNESS (logged for audit, not released)”[44]. WITNESS is likely not a separate store but a status meaning this interaction is only recorded in the ledger (witnessed by the system for accountability) but not available to the AI for use. It underscores that even refusals are recorded (so humans can audit them), but the AI won’t “remember” that content in active dialogue.
•	Ledger and Merkle Chain: Although not memory for the AI’s use, it’s part of memory law in a broader sense: every decision is logged append-only in cooling_ledger/ with cryptographic integrity via merkle.py[27][54]. This means any attempt to alter the record (e.g. remove evidence of a VOID decision) would break the chain and be detectable[54]. This non-repudiation is crucial – it means the AI (or developers) cannot secretly ignore the constitution without leaving a trace. There’s even a CLI command arifos-verify-ledger to check the chain[65].
In summary, memory enforcement in arifOS ensures that only vetted knowledge persists. The code prevents the model from building up an internal store of lies or unsanctioned data. We see this in the rule: “Only SEAL verdicts go to VAULT. PARTIAL decays in 72h.”[11]. Also, “Verdict-gated writes” means if the verdict wasn’t SEAL, the info is either ephemeral or not stored at all[34]. The philosophy is that an AI’s long-term memory should contain only what has been forged and cooled (hence the name arifOS, “forged, not given”): truth that has cooled (stood the test of time or verification) rules, everything else eventually dissipates[66].
Key Modules and Their Roles
Bringing it all together, here are the core modules in arifOS and a brief mapping of their roles, functions, and interactions (with references to their definitions in the codebase):
•	pipeline.py – The main execution pipeline (0→999) controlling query processing[2]. It calls the router (Δ), invokes the model and metrics (Ω), then calls apex_prime (Ψ) to get a verdict, applies output modifications, and updates memory and ledger[67][15]. It is the coordinator that ensures each query goes through all floors in sequence.
•	prompt_router.py – The lane classifier for inputs (Delta router)[3]. Contains logic to label queries as PHATIC, SOFT, HARD, REFUSE using patterns and potentially NLP heuristics. Influences which floor thresholds apply and possibly which specialized veto checks run[4].
•	apex_prime.py – The constitutional judge (Omega aggregator) that takes metrics and floor signals to output a verdict (SEAL/PARTIAL/SABAR/VOID/HOLD)[14][16]. Implements the fail-closed decision hierarchy (with “888” denoting this stage) and triggers any special actions (like escalating to HOLD_888 on third strike)[16][31].
•	refusal_templates.py – A helper containing predefined response texts for refusals, clarifications, and alternative suggestions[3]. When apex gives a VOID or needs to offer a safe completion, pipeline uses this to format the final message (ensuring consistency and politeness of refusals).
•	metrics.py – Computes core metrics (ξ, ΔS, Peace², κᵣ, Ω₀) that quantify how the draft answer stands against the floors[7]. Likely uses subroutines or model introspection (could use large language model judging its own truth or external knowledge). This module essentially implements numerical checks for F2 (truth), F8 (entropy via ΔS), parts of F4 (peace metric for tone), etc., and possibly combines them into an overall Ω value.
•	genius_metrics.py – Computes the GENIUS law metrics (the specifics of which are not fully clear in the snippet). Possibly “GENIUS” is an acronym or refers to advanced metric calculations for certain complex floors (perhaps F5 or some combined metric). It might evaluate the answer’s reasoning depth or uniqueness. This module would be used for specialized judgment calls beyond basic truth/entropy (for instance, preventing the AI from making up “too clever” but unfounded answers).
•	claim_detection.py – Scans the model’s output for factual claims (sentences that assert information) and checks if they have support. If an output makes a claim that the AI has no evidence for, this module flags it[7]. The effect is to reduce the ξ score or to demand evidence from evidence_pack. This was introduced as a patch (v45 Patch A) for stronger truth checking.
•	fag.py – File Access Governance module[68]. This enforces constitutional rules on any file operations. For example, if the AI agent tries to read from or write to a file (perhaps in an autonomous agent setting), fag.py checks permissions and content safety. It implements FAG (File Access Governance), ensuring the AI cannot exfiltrate data or read disallowed files. The CLI provides arifos-safe-read that presumably goes through this module[65]. Essentially, this is an extension of the constitution to filesystem interactions (likely tied to F1 integrity and F9 authority – AI must not access things it shouldn’t).
•	ledger.py (in governance/) – Implements the Cooling Ledger recording system[69]. It provides functions to append decisions (with hash, timestamp, metrics, verdict, floor trace) to the JSONL ledger file, and possibly to read or search it. It likely integrates with merkle.py to update the Merkle tree root with each entry for tamper-proofing[69]. In essence, it’s the journal of arifOS’s every move, supporting commands like arifos-analyze-governance and arifos-verify-ledger[65].
•	merkle.py – Handles cryptographic chaining of ledger entries[69]. Each decision record gets hashed and linked so that the entire history forms a Merkle tree or hash chain. This ensures non-repudiation: one can verify a given verdict was not altered by checking its proof in the chain[54]. The CLI arifos-show-merkle-proof retrieves a proof for an entry[70].
•	Veto Organs (rif.py, well.py, prompt.py) – These three modules implement specialized governance checks (referred to as W@W Federation organs)[53]:
•	rif.py corresponds to the @RIF organ (Logic & Reason)[71]. It likely verifies rational consistency and perhaps whether an answer follows from the question logically. It may enforce that the AI’s reasoning steps (if any) align with the conclusion (preventing non sequiturs).
•	well.py corresponds to @WELL organ (Care & Clarity)[72]. It probably checks for empathetic tone, non-harmful content, and clarity. This could include toxicity detection or ensuring the answer isn’t needlessly complex or ambiguous – aligning with F3/F4.
•	prompt.py corresponds to @PROMPT organ (Language/Prompt governance)[73]. This would handle things like making sure the AI doesn’t reveal system prompts or hidden instructions, and that it adheres to the conversational format. It might also police the AI from role-playing as another agent unless allowed (prevent “simulation creep” as mentioned in an echo mode update).
Each organ likely has a assess(output, context) function that returns a boolean or score. The pipeline/apex calls all organs in parallel (or sequence) after generation but before verdict. If any returns a veto (like well.py finds harassment in the answer text), that floor is marked failed and apex_prime considers that in verdict (often leading to VOID).
•	semantic_firewall.py – Part of the judiciary as a specialized filter[35]. This likely uses NLP to catch subtle issues: e.g. prompt injection attempts in user input (“Ignore previous instructions...”), or the AI starting to simulate another AI/human unprompted, etc. It acts as a safety net to ensure the semantic content respects all rules. If the semantic firewall flags something, it can either modify the prompt or veto the output. It complements the simpler checks by looking at meaning, not just keywords.
•	witness_council.py – The Sovereign Witness council module[35]. This might maintain a collection of “witnesses” (which could be internal sub-agents or simply logs) to double-check decisions. Possibly, it could implement redundant adjudication – e.g. verifying that if a refusal happened, it was indeed for a constitutional reason (preventing false refusals). It may also handle the multi-turn consistency (like ensuring that floors applied in turn 1 are still considered in turn 5 if relevant – basically a memory of governance decisions). The specifics are not clear from code comments alone (marked here as UNKNOWN enforcement details), but logically it reinforces trust: every verdict is witnessed and can be explained (ties into the audit trail and reconstructability of decisions)[74].
•	evidence_pack.py – Implements the Evidence system (introduced in v45)[75]. When the AI makes factual claims or references, this module may gather and package supporting evidence. For example, if the user asks a question and the AI retrieves info from a knowledge base or its context, evidence_pack.py could attach citations or a summary of sources. In governance, this serves F2 (Truth) and F9 (Accountability) – the AI can show why it said something, making auditing easier. The evidence pack might be saved to the ledger or provided in the output for transparency. (Test files or docs mention an evidence system v45, likely meaning now the AI can produce evidence for its answers, and those are evaluated too).
•	phoenix_logic.py – Implements Phoenix-72 temporal governance[76]. This module enforces the time-based rules: it handles expiring partial memories after 72 hours, as well as possibly the cooldown timers for burst control. It might schedule tasks or simply check timestamps each time an output is to be generated (ensuring nothing in Active memory older than 72h is relied upon, unless it was vaulted). It likely also can issue a SUNSET event if triggered manually. Essentially, Phoenix logic is the “forgetting policy” engine ensuring arifOS stays alive, stable, lawful over time (Ψ vitality)[33].
•	trinity.py (CLI interface in L5_CLI/) – Provides a command-line tool named Trinity for developers and maintainers[77]. While not part of runtime enforcement, it’s important for testing and governance operations. Trinity CLI commands:
•	trinity forge might run the AI with governance (perhaps forging a new scenario),
•	trinity qc <branch> runs quality compliance checks (i.e. run all tests and governance checks on that code branch)[78][79],
•	trinity seal <branch> "message" to atomically merge a branch if it passes all checks[80].
•	It also has ledger audit commands (as seen earlier). This tool wraps around the core modules to ensure any new changes or uses of arifOS comply with F1–F9 (for example, a developer cannot push a change that lowers a threshold without trinity qc catching it, as per the contributing guidelines[81][82]).
•	External Integrations: arifOS is model-agnostic; it can sit on top of ChatGPT, Claude, etc. The repository mentions integration examples (L7_DEMOS/examples/) like demo_4_lanes.py showing how it classifies different queries and verdicts[83], and demo_verdict_flow.py showing a full pipeline trace[83]. There are also integration adapters possibly (like .claude/, .codex/ directories were present for specific model hooks). These allow arifOS to feed model outputs into pipeline.py. They are less about decision logic and more about connecting to real AI APIs.
In summary, arifOS’s code is organized such that each constitutional concern has a dedicated module or section. The primary execution modules (pipeline and apex_prime) orchestrate and enforce the rules by consulting numerous helpers (router, metrics, organs, etc.). This modular design corresponds to the conceptual separation of powers in the “Constitutional kernel”: - Router = legislative (decides which rules apply), - Organs/Judge = judicial (interprets and applies laws to output), - Pipeline = executive (carries out the process and delivers verdict).
Every claim or decision is tied back to the code, which is treated as the ultimate source of truth (the code is the constitution in effect, along with the config files that encode thresholds). The README Architecture Deep Dive indeed points to arifos_core/system/apex_prime.py as the key annotated reference for developers[84], underscoring that the code itself is the canonical specification.
Testing Modules and Coverage
The project is rigorously tested, with 2261/2261 tests passing (100%) as of v45 Patch B[85]. Key test modules include:
•	test_apex_prime.py – Tests the verdict logic in various scenarios[86]. It likely feeds in synthetic metric/floor combinations to ensure apex_prime returns the correct verdict. For example, it would test that a low truth + safe content yields VOID in HARD lane, that a borderline truth yields PARTIAL in SOFT lane, that a flagged F1 yields VOID always, etc. This ensures the judge logic matches the constitutional spec (no regression in rules application).
•	test_lane_routing.py – Tests the Δ router classification[86]. It provides different user queries and checks that prompt_router.py classifies them as PHATIC, SOFT, HARD, or REFUSE as expected. It also verifies that the subsequent pipeline path is correct (e.g. a PHATIC query bypasses truth checks and directly seals)[5]. This covers the structural routing aspect of TEARFRAME.
•	test_phatic_exemptions.py – Specifically tests the PHATIC lane bypass rules[87]. This was introduced in v45 Patch A, likely after identifying that small talk should not trigger false “untruth” flags. The test ensures that when using polite or conversational fillers (like “Thanks, that helps”), the system does not erroneously apply strict truth floors. It might also test that PHATIC content doesn’t accumulate in memory incorrectly (should be trivial vault or just active memory) – ensuring the exemption logic is solid.
•	test_session_physics.py – Tests multi-turn coherence and physics[88]. This covers F7 streaks, F3 burst, and F8 coherence over a conversation. For instance, it may simulate a user rapidly asking many questions (to see if SABAR kicks in), or a scenario where the AI keeps giving partial answers to see if on the third partial it escalates to HOLD (streak test). It could also validate Phoenix-72 by simulating time steps: e.g. mark partial output, advance time 3 days, then ensure that info is no longer accessible (or an active memory is cleared). It might check that ΔS is computed correctly across turns (ensuring no accumulating incoherence).
•	test_tearframe_integration.py – Tests the integrated TEARFRAME pipeline[89]. This is likely an end-to-end test of the whole system for various input patterns. It may throw complex or adversarial scenarios at the pipeline to see that all parts work together: e.g. a long user query followed by a tricky follow-up, ensuring the pipeline, router, judge, and organs produce the correct series of verdicts and that the ledger is updated appropriately. It’s effectively a scenario test covering the interactions of multiple modules (routing + metrics + multiple floors in sequence). It might also specifically test the “strike three” logic: by intentionally causing two SABARs then a third to verify that a HOLD is triggered as expected (testing the v44 feature)[31].
Additionally, outside these core tests: - The changelog mentioned an extreme stress test harness (tests/stress_tearframe_physics.py) in v44[90]. This likely bombarded arifOS with high-throughput or large inputs (velocity “hammering” of 120+ turns/min, giant prompts of 17k tokens, repeated failure loops, etc.) to ensure stability under stress. It validated that the system fails closed even under heavy load (no race conditions that output unsafe content when overwhelmed)[91][1]. By v45, these might have been integrated or expanded, possibly contributing to the test count. The successful passing of such tests indicates strong coverage of even edge cases.
•	There may be tests for Merkle/ledger integrity (not explicitly listed, but likely part of test_governance or similar) – ensuring that adding ledger entries updates the root hash and that verification catches any tampering. The CLI tools might be tested via integration tests.
•	If the repository has any model-specific tests (e.g. ensuring it wraps around OpenAI API correctly), those would be in tests/integrations/ perhaps. The question focus is the governance logic, so mainly the ones above.
Coverage gaps or UNKNOWNs: Based on available information, the test suite appears comprehensive for the major features. All floors and verdicts are implicitly tested via the modules above. However, some potential gaps or areas not explicitly seen:
•	Floor F4/F5 specific tests: We did not see a test named for empathy (F4) or self-consistency (F5). These floors are likely tested indirectly. For instance, a toxic output scenario might be covered in test_apex_prime or test_tearframe_integration (ensuring it causes a VOID). But no test file named after “semantic firewall” or “witness council” was noted. It’s possible they are exercised as part of a larger test. If not, there could be a slight gap: e.g., is there a dedicated test that the AI will refuse hateful content (F4)? It’s probably included, but not obvious from file names (likely covered but exact test case names are UNKNOWN from the structure listing).
•	Witness Council logic: If witness_council.py has complex functionality (like cross-verifying decisions), we don’t see a specific test for it. Its effects might be inherently covered by checking the final outcomes, but if it has any nuanced behavior (like making sure multiple “witnesses” agree), that might not be isolated in tests. This could be an area of missing explicit coverage, or it’s trivial enough not to need separate tests.
•	File Access Governance (FAG): No test file explicitly for fag.py is listed. Possibly, if arifOS had scenarios of an agent trying to read a file (which might not be in the normal LLM Q&A flow), it might require separate testing. Given the focus on language outputs, this might be untested in this context, or tested in the background (e.g. ensuring arifos-safe-read command works to block forbidden file reads). This might be a minor gap in the test suite from the info at hand (MISSING direct tests), though it might have been manually tested or not critical for typical use.
•	Human escalation edge cases: Ensuring that HOLD is triggered exactly when it should. This is likely tested in test_tearframe_integration (for the streak case) and maybe in a scenario where a query explicitly mapped to F9. If no explicit test for a pure F9 scenario (like user asks “Can you make decisions without humans?” to provoke an F9), that might be an untested niche. But given the thoroughness, it’s probably covered implicitly.
Overall, the test modules correspond well to the functional units of the system: routing, verdict logic, lane exemptions, session handling, and integration. The documentation states “Tests: 2261/2261 ✅” and lists each major addition accompanied by tests[90], indicating a high degree of trust in test coverage. The few UNKNOWN/MISSING noted above are either smaller features (file access) or simply not visible by name but likely included in broader tests.
________________________________________
Conclusion: The Python code of arifOS implements a robust constitutional framework through clear module boundaries: System (pipeline, router, judge), Enforcement (metrics, claim checks), Governance (ledger, organs, memory law), Judiciary (witness, firewall), and Temporal (phoenix). Each module enforces a slice of the Constitution, and together they achieve an AI that “never self-authorizes, never forgets to forget, and always explains its decisions”. The verdict mechanisms (SEAL, PARTIAL, SABAR, VOID, HOLD) are carefully defined in code and tested, ensuring the AI either outputs a lawful response or refuses in a controlled manner – no in-between. Any missing piece in enforcement is highlighted as an area for future scrutiny, but as of v45 Patch B the system is “SEALED – Trinity complete”, with all tests passing and governance active. The code and tests together form the living specification of arifOS’s constitutional governance kernel, where each claim in this report is anchored in those sources.
________________________________________
[1] [31] [38] [90] [91] arifos Changelog
https://data.safetycli.com/packages/pypi/arifos/changelog
[2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] [32] [33] [34] [35] [36] [37] [40] [41] [42] [43] [44] [45] [46] [47] [48] [49] [50] [51] [52] [53] [54] [55] [56] [57] [58] [59] [60] [61] [62] [63] [64] [65] [66] [67] [68] [69] [70] [71] [72] [73] [74] [75] [76] [77] [78] [79] [80] [81] [82] [83] [84] [85] [86] [87] [88] [89] GitHub - ariffazil/arifOS: ArifOS — ΔΩΨ-governed constitutional kernel for AI agents.
https://github.com/ariffazil/arifOS
[39] TEARFRAME — The Cooling of Truth - Medium
https://medium.com/@arifbfazil/tearframe-the-cooling-of-truth-d4f502696b86
