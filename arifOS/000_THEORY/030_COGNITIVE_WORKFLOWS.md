---
title: "030_THEORY_COGNITIVE_WORKFLOWS"
version: "v55.5"
epoch: "2026-02-03"
status: "DRAFT"
---

# 030 COGNITIVE WORKFLOWS — GOVERNED REFLECTION (Draft)

**Motto:** *Thinking is a Loop, Not a Line.*

## I. THE PROBLEM: HALLUCINATION VELOCITY
Standard LLM "Chain of Thought" (CoT) is un-governed.
- Step 1: "I think X" (Hallucination)
- Step 2: "Because X, implies Y" (Compounded Error)
- Step 3: "Therefore Z" (Confident Nonsense)

**Traditional CoT accelerates entropy.**

## II. THE SOLUTION: CONSTITUTIONAL BREAKPOINTS
Instead of a continuous stream of thought, we introduce **Constitutional Breakpoints** (floors) between reflection steps.

```
[Thought N] 
    ↓ 
[AGI_REFLECT Tool] — F2 Truth & F4 Clarity Check
    ↓
[Verdict: SABAR/VOID] —> "Thought rejected: Premise X is false."
    ↓
[Revision] —> [Thought N+1]
```

## III. IMPLEMENTATION PLAN (v55.5)

### 1. New Tool: `agi_reflect`
A specialized AGI primitive focused solely on querying the generated thought against critical floors.

**Input:**
- `thought`: The text generated by the LLM.
- `context`: The original query/goal.
- `history`: Previous verdicts.

**Floors Enforced:**
- **F2 (Truth):** Verification of claims against known state.
- **F4 (Clarity):** Logical consistency check (entropy reduction).
- **F7 (Humility):** Checking for overconfidence markers ("undoubtedly", "always").
- **F10 (Ontology):** Checking for self-personification.

### 2. The Workflow Loop
1. **User Query**: "How do I..."
2. **LLM**: *Generates Initial Plan* -> Calls `agi_reflect(plan)`
3. **ArifOS**: Checks plan.
   - If unsafe: Returns VOID + Specific reason ("F2 Violation: Library X does not exist").
4. **LLM**: *Reading VOID* -> "Ah, I must revise." -> Generates Plan B -> Calls `agi_reflect(plan_b)`
5. **ArifOS**: Checks plan.
   - If safe: Returns SEAL.
6. **LLM**: Executes Plan B.

### 3. Thermodynamic Cost
Running this loop increases latency and token cost ("Energy").
**Mitigation:** `reflection_budget` (e.g., max 3 loops).
**Genius Equation Impact:** `E` (Efficiency) drops, but `A` (Accuracy) rises dramatically. Favorable trade-off for complex tasks.

## IV. EXECUTION
This capability is **partially implemented** in the kernel (`reflect` method exists) but **not exposed** as a primary loop.

**Recommendation:**
1. Upgrade `AGINeuralCore.reflect` to use rigorous heuristics (not just string matching).
2. Expose `agi_reflect` in `canonical_trinity.py`.
3. Update System Prompt to encourage use of `agi_reflect` for complex reasoning.
